{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rUBotCoop Autonomous Navigation Laboratory Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autonomous navigation refers that the robot is able to move autonomously around the environment avoiding any obstacle.\n",
    "\n",
    "In a hospital, a delivery robot carries samples or food from one room to another. \n",
    "\n",
    "The main objectives are:\n",
    "- Create a real robot and its virtual model for simulation purposes\n",
    "- locate the robot in our hospital environment\n",
    "- perform autonomous navigation in the Hospital environment\n",
    "- generate and store a map of the hospital \n",
    "- use SLAM (Simultaneous Localization and Mapping) techniques to find an optimal trajectory to reach a speciffic hospital target position\n",
    "\n",
    "To fulfill these objectives, use the VS Code and clone the repository:\n",
    "\n",
    "https://github.com/manelpuig/rUBotCoop_LabProject\n"
   ]
  },
  {
   "source": [
    "First of all, open the .bashrc file and verify the ROS_HOSTNAME and ROS_MASTER_URI environment variables and source to the proper workspace:\n",
    "\n",
    "source ~/rUBotCoop_LabProject/devel/setup.bash\n",
    "\n",
    "export ROS_IP=192.168.18.83\n",
    "\n",
    "export ROS_MASTER_URI=http://192.168.18.83:11311"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Let's now review the different Project objectives:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### rUBotCoop model generation\n",
    "\n",
    "To perform autonomous Navigation, different sensors are needed and installed in the robot:\n",
    "- a two-dimensional camera: correspondas to RBPi camera\n",
    "- a Laser Distance Sensor (LDS): is the unidirectional distance sensor of the GoPiGo3 kit\n",
    "- a 360º LIDAR sensor: corresponds to the EAI YDLIDAR X4 (https://www.robotshop.com/es/es/escaner-laser-360-ydlidar-x4.html)\n",
    "\n",
    "We have created a speciffic ROS Package to define a complete model of rUBotCoop robot including these sensors. This package is called \"gopigo3_description\" and the robot model is saved in URDF folder as \"gopigo3.gazebo\" file. This URDF model contains the SDF (Gazebo tags) for a complete, dynamic simulation. This package provides the gopigo3_rviz.launch launch file to interactively visualize the model in RViz.\n",
    "\n",
    "Launch the ROS visualization tool to check that the model is properly built. This tool is RViz and only represents the robot visual features. You have available all the options to check every aspect of the appearance of the model:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "roslaunch gopigo3_description gopigo3_rviz.launch"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "<img src=\"./Images/LP01_full_model_rviz.png\">"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Some modifications in the initial model \"gopigo3_init.gazebo\" have been made to:\n",
    "- locate the LIDAR in the correct position\n",
    "- locate the camera axis in front position to see properly"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Special attention has to be done to the YDLIDAR sensor.\n",
    "\n",
    "- YDLIDAR X4 is a 360-degree two-dimensional rangefinder (hereinafter referred to as X4) developed by YDLIDAR team. \n",
    "- Based on the principle of triangulation, it is equipped with related optics, electronics and algorithm design to achieve high-frequency and high-precision distance measurement. \n",
    "- The mechanical structure rotates 360 degrees to continuously output the angle information as well as the point cloud data of the scanning environment while ranging.\n",
    "-10m Ranging distance (2cm absolute error)"
   ]
  },
  {
   "source": [
    "<img src=\"./Images/LP01_ydlidar.png\">"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### rUBotCoop in world environment\n",
    "\n",
    "In robotics research, always before working with a real robot, we simulate the robot behaviour in a virtual environment close to the real one. The dynamic simulation of a robot, is a better approach to examining the actual behavior of the robot rather than just using software. Rigid body mechanics, including mass and inertia, friction, damping, motor controllers, sensor detection properties, noise signals, and every aspect of the robot and the environment that can be retained in a model with reasonable accuracy is much less expensive when replicated in a simulator than if you tried to do this with physical hardware.\n",
    "\n",
    "Gazebo is an open source 3D robotics simulator and includes an ODE physics engine and OpenGL rendering, and supports code integration for closed-loop control in robot drives. This is sensor simulation and actuator control.\n",
    "\n",
    "A speciffic ROS Package called \"gazebo_control\" have been created for this purpose."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roslaunch gazebo_control spawn.launch\n",
    "roslaunch gopigo3_description gopigo3_rviz.launch"
   ]
  },
  {
   "source": [
    "<img src=\"./Images/LP02_rubotcoop_spawn.png\">"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "<img src=\"./Images/LP02_rubotcoop_spawn_rviz.png\">"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "<img src=\"./Images/LP05_rqt_gopigo.png\">"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "In order to kill the previous Gazebo process, type:\n",
    "\n",
    "killall gzserver && killall gzclient"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Design the Project world\n",
    "\n",
    "Here we have first to design the project world, for exemple a hospital floor with different rooms where our rUBotCoop delivery robot has to navigate autonomously.\n",
    "\n",
    "There is a very useful and simple tool to design a proper world: Building editor\" in gazebo.\n",
    "\n",
    "Open gazebo as superuser:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sudo gazebo"
   ]
  },
  {
   "source": [
    "You can build your world using \"Building Editor\" i Edit menu"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "<img src=\"./Images/LP03_BuildingWorld1_1.png\">"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "You can save:\n",
    "- the generated model in a model folder\n",
    "- the generated world (world1.world) in the world folder.\n",
    "\n",
    "Now, spawn the rUBotCoop robot in our generated world. You have to create a \"rubot_navigation.launch\" file:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<launch>\n",
    "  <arg name=\"world\" default=\"world1.world\"/> \n",
    "  <arg name=\"model\" default=\"gopigo3.gazebo\" />\n",
    "  <arg name=\"x_pos\" default=\"0.0\"/>\n",
    "  <arg name=\"y_pos\" default=\"0.0\"/>\n",
    "  <arg name=\"z_pos\" default=\"0.0\"/>\n",
    "\n",
    "  <include file=\"$(find gazebo_ros)/launch/empty_world.launch\">\n",
    "    <arg name=\"world_name\" value=\"$(find gazebo_control)/worlds/$(arg world)\"/>\n",
    "    <arg name=\"paused\" value=\"false\"/>\n",
    "    <arg name=\"use_sim_time\" value=\"true\"/>\n",
    "    <arg name=\"gui\" value=\"true\"/>\n",
    "    <arg name=\"headless\" value=\"false\"/>\n",
    "    <arg name=\"debug\" value=\"false\"/>\n",
    "  </include>\n",
    "\n",
    "  <param name=\"robot_description\" textfile=\"$(find gopigo3_description)/urdf/$(arg model)\" />\n",
    "  \n",
    "  <node pkg=\"gazebo_ros\" type=\"spawn_model\" name=\"spawn_urdf\"\n",
    "    args=\"-urdf -model gopigo3 -x $(arg x_pos) -y $(arg y_pos) -z $(arg z_pos) -param robot_description\" />\n",
    "\n",
    "</launch>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roslaunch gazebo_control rubot_navigation.launch"
   ]
  },
  {
   "source": [
    "<img src=\"./Images/LP04_BuildingWorld1_2.png\">"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "To control the robot with the Keyboard you type:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rosrun key_teleop key_teleop.py /key_vel:=/cmd_vel"
   ]
  },
  {
   "source": [
    "In order to kill the previous Gazebo process, type:\n",
    "\n",
    "killall gzserver && killall gzclient"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### ROS autonomous navigation in the Hospital environment\n",
    "\n",
    "Once the world has been generated we will create a ROS Package \"rubot_control\" to perform the autonomous navigation "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "<img src=\"./Images/LP07_rubot_control.png\">"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ~/rUBotCoop_LabProject/src\n",
    "catkin_create_pkg rubot_control rospy std_msgs sensor_msgs geometry_msgs nav_msgs\n",
    "cd ..\n",
    "catkin_make"
   ]
  },
  {
   "source": [
    "We will create now different navigation python files in \"src\" folder:\n",
    "- rubot_autonomous_navigation1.py\n",
    "- rubot_autonomous_navigation2.py"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "we will create also a \"launch\" folder including the corresponding launch files:\n",
    "- rubot_nav1.launch\n",
    "- rubot_nav2.launch"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Test the autonomous navigation obtained using the python file typing:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roslaunch rubot_control rubot_nav2.launch"
   ]
  },
  {
   "source": [
    "Careful:\n",
    "- we have included in launch file: gazebo spawn, rviz visualization and node in navigation python file\n",
    "- In rviz you have to change the fixed frame to \"odom\" frame"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "To control the robot with the Keyboard you type:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rosrun key_teleop key_teleop.py /key_vel:=/cmd_vel"
   ]
  },
  {
   "source": [
    "<img src=\"./Images/LP08_rubot_nav_key.png\">"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "To perform the Autonomous Navigation we have designed different python files:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "- \"rubot_autonomous_navigation1.py\": The Python script makes the robot wander in the environment while avoiding the obstacles. To do this, we have implemented the following rules in our script: \n",
    "    - If there is no obstacle, move forward at a reference speed of 0.8 m/s. \n",
    "    - If the range provided by the distance sensor is lower than 2 meters, go back and rotate counter-clockwise until avoiding the obstacle. \n",
    "    - Since the distance sensor throws unidirectional measurements, we should check the measurements from the LDS to find if there are obstacles to the sides, and the threshold should be lower than 1.6 meters. If obstacles are detected, go back and rotate counter-clockwise faster to avoid the obstacle and not get stuck on it."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "<img src=\"./Images/01_rubot_nav_rqt.png\">"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Project Task\n",
    "\n",
    "There are 2 main tasks:\n",
    "- generate a proper Hospital world with different rooms \n",
    "- Create another rubot_autonomous_navigation.py file to improve the navigation process of our rUBotCoop"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}