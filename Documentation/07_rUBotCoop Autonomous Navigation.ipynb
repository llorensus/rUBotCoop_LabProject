{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rUBotCoop Autonomous Navigation Laboratory Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autonomous navigation refers that the robot is able to move autonomously around the environment avoiding any obstacle.\n",
    "\n",
    "In a hospital, a delivery robot carries samples or food from one room to another. \n",
    "\n",
    "The main objectives are:\n",
    "- Create a real robot and its virtual model for simulation purposes\n",
    "- locate the robot in our hospital environment\n",
    "- perform autonomous navigation in the Hospital environment\n",
    "- generate and store a map of the hospital \n",
    "- use SLAM (Simultaneous Localization and Mapping) techniques to find an optimal trajectory to reach a speciffic hospital target position\n",
    "\n",
    "let's see how to fulfill these objectives"
   ]
  },
  {
   "source": [
    "### ROS navigation packages\n",
    "First, let's prepare your machine with the required ROS packages needed for the navigation stack:\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sudo apt install ros-melodic-navigation ros-melodic-amcl ros-melodic-map-server ros-melodic-move-base ros-melodic-urdf ros-melodic-xacro ros-melodic-compressed-image-transport ros-melodic-rqt-image-view"
   ]
  },
  {
   "source": [
    "And finally the slam_gmapping package, that is already available in its binary version"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sudo apt-get install ros-melodic-slam-gmapping"
   ]
  },
  {
   "source": [
    "Be sure about the ROS_HOSTNAME and ROS_MASTER_URI variables in the .bashrc file: (at home are)\n",
    "\n",
    "export ROS_HOSTNAME=192.168.18.52\n",
    "export ROS_MASTER_URI=http://192.168.18.52:11311"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## rUBotCoop model generation\n",
    "\n",
    "To perform autonomous Navigation, different sensors are needed and installed in the robot:\n",
    "- a two-dimensional camera: correspondas to RBPi camera\n",
    "- a Laser Distance Sensor (LDS): is the unidirectional distance sensor of the GoPiGo3 kit\n",
    "- a 360º LIDAR sensor: corresponds to the EAI YDLIDAR X4 (https://www.robotshop.com/es/es/escaner-laser-360-ydlidar-x4.html)\n",
    "\n",
    "We have created a speciffic ROS Package to define a complete model of rUBotCoop robot including these sensors. This package is called \"gopigo3_description\" and the robot model is saved in URDF folder as \"gopigo3.gazebo\" file.\n",
    "\n",
    "Launch the ROS visualization tool to check that the model is properly built. This tool is RViz and only represents the robot visual features. You have available all the options to check every aspect of the appearance of the model:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "roslaunch gopigo3_description gopigo3_rviz.launch"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "<img src=\"./Images/LP01_full_model_rviz.png\">"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code contains two new ROS packages as follows: \n",
    "- gopigo3_description, which contains the URDF model plus the SDF (Gazebo tags) for a complete, dynamic simulation. This package provides the gopigo3_rviz.launch launch file to interactively visualize the model in RViz.\n",
    "- virtual_slam contains the virtual robot simulation itself, plus the launch files needed to run SLAM in Gazebo.\n",
    "\n",
    "Then, rebuild the workspace so that it is known to your ROS installation:"
   ]
  },
  {
   "source": [
    "## rUBotCoop in world environment\n",
    "\n",
    "In robotics research, always before working with a real robot, we simulate the robot behaviour in a virtual environment close to the real one. The dynamic simulation of a robot, which, conceptually, is a better approach to examining the actual behavior of the robot rather than just using software. Rigid body mechanics, including mass and inertia, friction, damping, motor controllers, sensor detection properties, noise signals, and every aspect of the robot and the environment that can be retained in a model with reasonable accuracy is much less expensive when replicated in a simulator than if you tried to do this with physical hardware.\n",
    "\n",
    "Gazebo is an open source 3D robotics simulator and includes an ODE physics engine and OpenGL rendering, and supports code integration for closed-loop control in robot drives. This is sensor simulation and actuator control.\n",
    "\n",
    "A speciffic ROS Package called \"gazebo_control\" have been created for this purpose."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roslaunch gazebo_control spawn.launch\n",
    "roslaunch gopigo3_description gopigo3_rviz.launch"
   ]
  },
  {
   "source": [
    "<img src=\"./Images/LP02_rubotcoop_spawn.png\">"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "<img src=\"./Images/LP02_rubotcoop_spawn_rviz.png\">"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "In order to kill the previous Gazebo process, type:\n",
    "\n",
    "killall gzserver && killall gzclient"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Design the Project world\n",
    "\n",
    "Here we have first to design the project world, for exemple a hospital floor with different rooms where our rUBotCoop delivery robot has to navigate autonomously.\n",
    "\n",
    "There is a very useful and simple tool to design a proper world: Building editor\" in gazebo.\n",
    "\n",
    "Open gazebo as superuser:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sudo gazebo"
   ]
  },
  {
   "source": [
    "You can build your world using \"Building Editor\" i Edit menu"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "<img src=\"./Images/LP03_BuildingWorld1_1.png\">"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "You can save the generated world (world1.world) in the world folder.\n",
    "\n",
    "Now, spawn the rUBotCoop robot in our generated world:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roslaunch rubot_control rubot_navigation_world1.launch"
   ]
  },
  {
   "source": [
    "<img src=\"./Images/LP04_BuildingWorld1_2.png\">"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Open RVIZ to see the sensors readings and add the laser_scan sensor:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roslaunch rubot_control rubot_rviz.launch"
   ]
  },
  {
   "source": [
    "Control the robot with the Keyboard"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rosrun key_teleop key_teleop.py /key_vel:=/cmd_vel"
   ]
  },
  {
   "source": [
    "To test this sensor, it is better to use a Python script that makes the robot wander in the environment while avoiding the obstacles. To do this, we have implemented the following rules in our script: \n",
    "- If there is no obstacle, move forward at a reference speed of 0.8 m/s. \n",
    "- If the range provided by the distance sensor is lower than 2 meters, go back and rotate counter-clockwise until avoiding the obstacle. \n",
    "- Since the distance sensor throws unidirectional measurements, we should check the measurements from the LDS to find if there are obstacles to the sides, and the threshold should be lower than 1.6 meters. If obstacles are detected, go back and rotate counter-clockwise faster to avoid the obstacle and not get stuck on it.\n",
    "\n",
    "This simple algorithm is implemented in the wanderAround.py script, and can be found under the ./virtual_slam/scripts/wanderAround.py folder.\n",
    "\n",
    "First Kill the previous Gazebo process:\n",
    "killall gzserver && killall gzclient"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rosrun rubot_control rubot_autonomous_navigation.py"
   ]
  },
  {
   "source": [
    "<img src=\"./Images/01_Navigation_key.png\">"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}