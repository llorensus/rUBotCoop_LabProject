{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rUBotCoop Autonomous Navigation Using Gazebo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using SLAM (short for Simultaneous Localization and Mapping) techniques, you will be able to execute autonomous navigation with GoPiGo3.\n",
    "\n",
    "SLAM is a technique used in robotics to explore and map an unknown environment while estimating the pose of the robot itself. As it moves all around, it will be acquiring structured information of the surroundings by processing the raw data coming from its sensors.\n",
    "\n",
    "For optimal and easy-to-understand coverage of the topic of SLAM, we will implement a 360º-coverage Laser Distance Sensor (LDS) in the virtual robot. \n",
    "\n",
    "There are low-cost versions of this sensor technology, such as EAI YDLIDAR X4 (available at https://www.robotshop.com/es/es/escaner-laser-360-ydlidar-x4.html), which is the one we will make use of in the next chapter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy its files to the ROS workspace to have them available, and leave the rest outside of the src folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp -R ~/Hands-On-ROS-for-Robotics-Programming/Chapter8_Virtual_SLAM ~/rUBotCoop_ws/src/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code contains two new ROS packages as follows: \n",
    "- gopigo3_description, which contains the URDF model plus the SDF (Gazebo tags) for a complete, dynamic simulation. This package provides the gopigo3_rviz.launch launch file to interactively visualize the model in RViz.\n",
    "- virtual_slam contains the virtual robot simulation itself, plus the launch files needed to run SLAM in Gazebo.\n",
    "\n",
    "Then, rebuild the workspace so that it is known to your ROS installation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ~/rUBotCoop_ws\n",
    "catkin_make "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROS navigation packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's prepare your machine with the required ROS packages needed for the navigation stack:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sudo apt install ros-melodic-navigation ros-melodic-amcl ros-melodic-map-server ros-melodic-move-base ros-melodic-urdf ros-melodic-xacro ros-melodic-compressed-image-transport ros-melodic-rqt-image-view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally the slam_gmapping package, that is already available in its binary version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sudo apt-get install ros-melodic-slam-gmapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test this sensor, it is better to use a Python script that makes the robot wander in the environment while avoiding the obstacles. To do this, we have implemented the following rules in our script: \n",
    "- If there is no obstacle, move forward at a reference speed of 0.8 m/s. \n",
    "- If the range provided by the distance sensor is lower than 2 meters, go back and rotate counter-clockwise until avoiding the obstacle. \n",
    "- Since the distance sensor throws unidirectional measurements, we should check the measurements from the LDS to find if there are obstacles to the sides, and the threshold should be lower than 1.6 meters. If obstacles are detected, go back and rotate counter-clockwise faster to avoid the obstacle and not get stuck on it.\n",
    "\n",
    "This simple algorithm is implemented in the wanderAround.py script, and can be found under the ./virtual_slam/scripts/wanderAround.py folder.\n",
    "\n",
    "First Kill the previous Gazebo process:\n",
    "killall gzserver && killall gzclient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roslaunch virtual_slam gopigo3_world.launch\n",
    "rosrun virtual_slam wanderAround.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/08_gazebo_lidar2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kill the previous Gazebo process, type:\n",
    "killall gzserver && killall gzclient"
   ]
  },
  {
   "source": [
    "### Exercise: rUBotCoop autonomous navigation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "The objective of this exercise is to improve the autonomous navigation in a customized world.\n",
    "\n",
    "For this purpose, you will have to:\n",
    "- design your proper world\n",
    "- improve the geometry and dynamics of your rUBOtCoop URDF model\n",
    "- improve and modify the wanderAround.py script"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Be sure about the ROS_HOSTNAME and ROS_MASTER_URI variables in the .bashrc file: (at home are)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export ROS_HOSTNAME=192.168.18.52\n",
    "export ROS_MASTER_URI=http://192.168.18.52:11311"
   ]
  },
  {
   "source": [
    "Spawn the rUBotCoop robot in our generated world:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roslaunch rubot_control rubot_navigation_world1.launch"
   ]
  },
  {
   "source": [
    "Open RVIZ to see the sensors readings and add the laser_scan sensor:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roslaunch rubot_control rubot_rviz.launch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rosrun rubot_control rubot_autonomous_navigation.py"
   ]
  },
  {
   "source": [
    "<img src=\"./Images/07_rubot_nav_exercise.png\">"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}